# relAI p√• Raspberry Pi 5 ‚Äî nul√§ge (k√∂rbart) + statuslogg (video+audio+HA)

Det h√§r repot dokumenterar v√•rt faktiska ‚Äúnu-l√§ge‚Äù p√• Raspberry Pi 5 och hur man f√•r ig√•ng ett minimalt, verifierbart system:

- **Home Assistant** i Docker (framtida dashboard/automationer/Assist i mobilen)
- **Vision inference** (Google Coral / EdgeTPU) i Docker (`vision-service`)
- **Vision loop ‚Üí Home Assistant-sensorer** (snapshot ‚Üí `/infer` ‚Üí postar sensorer i HA)
- **Audio loop** (webbkamera-mic ‚Üí enkel realtids-score ‚Üí HTTP/HA)
- En **minimal FastAPI ‚Äúdashboard‚Äù** anv√§ndes som testmottagare f√∂r att bevisa att audio kan skicka live

M√•let √§r att bygga upp systemet **stegvis**, med tydliga kommandon och s√• lite gissning som m√∂jligt.

---

## Status (senast verifierat)

‚úÖ `vision-service` svarar p√• `http://127.0.0.1:5052/health`  
‚úÖ Kamera-snapshot via `ffmpeg` fungerar (`/dev/video0 ‚Üí /tmp/frame.jpg`)  
‚úÖ `infer`-endpoint fungerar (`/infer` tar emot bild och svarar JSON)  
‚úÖ `relai-audio-loop.service` k√∂r (systemd)  
‚úÖ `relai-dashboard-mini.service` k√∂r (systemd)  
üü° `relai-vision-loop.service` finns och k√∂rs via systemd, men kameradrivrutinen kan kr√§va format-tvingning (se ‚ÄúFels√∂kning: V4L2 Invalid argument‚Äù)

### Senaste snabbtest (2025-12-30)
- `curl http://127.0.0.1:5052/health` ‚Üí `{"ok":true,"model":"ssdlite_mobiledet_coco_qat_postprocess_edgetpu.tflite"}`
- `ffmpeg ... /dev/video0 ... /tmp/frame.jpg` ‚Üí skapade fil (~55K)
- `curl -F file=@/tmp/frame.jpg http://127.0.0.1:5052/infer` ‚Üí fungerade (men kunde ge `detections: []` beroende p√• bildinneh√•ll)

---

## Milj√∂ (host)

- **Raspberry Pi 5 Model B**
- **OS**: Debian GNU/Linux 12 (bookworm), **aarch64**
- **Kamera**: UGREEN UVC + USB Audio (mic)
- **Coral**: EdgeTPU USB (syns som `18d1:9302` i `lsusb`)

### Audio-enhet (UGREEN Camera)
`arecord -l` (exempel):
- `card 0: Camera [UGREEN Camera], device 0: USB Audio [USB Audio]`

`arecord --dump-hw-params` visar typiskt:
- FORMAT: `S16_LE`
- CHANNELS: `2`
- RATE: `8000‚Äì48000`

---

## Repo & mappar (lokalt p√• Pi)

Exempel (kan variera):
- `~/vision_service_bookworm/` ‚Äì vision/Coral-relaterat repo (detta repo)
- `~/coral-test-data/` ‚Äì modeller/testdata (p√• hosten)
- `~/homeassistant/config/` ‚Äì Home Assistant config-volym (p√• hosten)

I repot:
- `vision/relai-vision-loop/` ‚Äì **Vision loop ‚Üí HA** (Python)

---

## 1) Home Assistant (Docker)

### Starta container
```bash
mkdir -p ~/homeassistant/config

docker run -d \
  --name homeassistant \
  --restart unless-stopped \
  --network host \
  -e TZ="Europe/Stockholm" \
  -v ~/homeassistant/config:/config \
  ghcr.io/home-assistant/home-assistant:stable
```

### √ñppna UI
```bash
hostname -I
```
√ñppna:
- `http://<PI-IP>:8123`

### Bluetooth (valfritt)
Om du beh√∂ver Bluetooth:
- installera `bluez` p√• host
- skapa om containern med cap-add + dbus mount

```bash
sudo apt update
sudo apt install -y bluez

docker stop homeassistant
docker rm homeassistant

docker run -d \
  --name homeassistant \
  --restart unless-stopped \
  --network host \
  --cap-add=NET_ADMIN \
  --cap-add=NET_RAW \
  -v /run/dbus:/run/dbus:ro \
  -e TZ="Europe/Stockholm" \
  -v ~/homeassistant/config:/config \
  ghcr.io/home-assistant/home-assistant:stable
```

---

## 2) Vision-service (Docker + Coral)

> PyCoral p√• Bookworm + Python 3.11 √§r ofta struligt. Vi k√∂r d√§rf√∂r inference i container d√§r EdgeTPU-runtime + pycoral kommer via apt (bullseye/py39-baserat uppl√§gg).

### Health-check
```bash
curl -sS http://127.0.0.1:5052/health ; echo
```

### Snapshot ‚Üí infer (snabb verifiering)
```bash
rm -f /tmp/frame.jpg
ffmpeg -hide_banner -loglevel error -f v4l2 -video_size 640x480 -i /dev/video0 -frames:v 1 -q:v 4 -y /tmp/frame.jpg
ls -lh /tmp/frame.jpg

curl -sS -F "file=@/tmp/frame.jpg" http://127.0.0.1:5052/infer | head -c 400; echo
```

**Obs:** `detections: []` betyder bara att modellen inte ser n√•got den klassar √∂ver tr√∂skeln i just den bilden.

---

## 3) Vision loop ‚Üí Home Assistant (sensorer)

Vision-loopen tar snapshots, skickar dem till `vision-service` och postar resultat som sensorer i Home Assistant.

### Sensornamn i Home Assistant
- `sensor.vision_top_label`
- `sensor.vision_top_score`
- `sensor.vision_person_count`
- `sensor.vision_total_ms`

### Labels-fil (COCO)
F√∂r att f√• ‚Äúperson‚Äù ist√§llet f√∂r bara id, anv√§nd en labels-fil (ex):
- `/home/tuff/coral-test-data/coco_labels.txt`

Hitta den:
```bash
find ~/coral-test-data -maxdepth 2 -type f \( -iname "*label*txt" -o -iname "*coco*txt" \)
```

### Manuell k√∂rning (f√∂r test)
```bash
cd ~/vision_service_bookworm/vision/relai-vision-loop
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# token h√§mtas s√§kert fr√•n secrets:
set -a
source /home/tuff/.relai_secrets
set +a

HA_URL="http://127.0.0.1:8123" \
VISION_URL="http://127.0.0.1:5052" \
VIDEO_DEV="/dev/video0" \
LABELS_PATH="/home/tuff/coral-test-data/coco_labels.txt" \
INTERVAL_S="2.0" \
python ./vision_loop_ha.py
```

### Systemd (k√∂r alltid)
Secrets (lokalt, aldrig i git):
- `/home/tuff/.relai_secrets` inneh√•ller:
  - `HA_TOKEN=...`

Loggar:
```bash
journalctl -u relai-vision-loop.service -f
```

---

## 4) Audio loop (webbkamera-mic ‚Üí score ‚Üí HTTP)

> Audio-loopen analyserar mikrofonen och skickar A/B-score till en endpoint. Ursprungligen testades detta mot mini-dashboard (`/set`).

Installera f√∂ruts√§ttningar:
```bash
sudo apt update
sudo apt install -y ffmpeg python3-venv
```

Verifiera ljud-enhet:
```bash
arecord -l
arecord -D hw:0,0 --dump-hw-params -d 1 /dev/null
```

Testa inspelning:
```bash
arecord -D hw:0,0 -f S16_LE -c 2 -r 48000 -d 3 test.wav
ls -lh test.wav
```

K√∂r audio-loop (exempel):
```bash
cd ~/relai-audio-loop
python3 -m venv .venv
source .venv/bin/activate
pip install requests

ALSA_DEVICE="plughw:0,0" \
DASHBOARD_SET_URL="http://127.0.0.1:8000/set" \
python ./audio_loop_webcam.py
```

**Obs:** `aplay` kan faila om Pi saknar playback-enhet ‚Äì det p√•verkar inte inspelning/analys.

---

## 5) Mini-dashboard (FastAPI) ‚Äî testmottagare f√∂r /set

Detta √§r inte Home Assistant-dashboard, utan en minimal mottagare f√∂r att bevisa ‚Äúaudio kan skicka live‚Äù.

Skapa och starta:
```bash
mkdir -p ~/relai-dashboard-mini
cd ~/relai-dashboard-mini
python3 -m venv .venv
source .venv/bin/activate
pip install fastapi uvicorn

cat > app.py <<'PY'
from fastapi import FastAPI
from fastapi.responses import JSONResponse

app = FastAPI()
state = {"A": 0.0, "B": 0.0}

@app.get("/health")
def health():
    return {"ok": True, "state": state}

@app.get("/set")
def set_values(A: float = 0.0, B: float = 0.0):
    state["A"] = float(A)
    state["B"] = float(B)
    return JSONResponse({"ok": True, "state": state})
PY

uvicorn app:app --host 0.0.0.0 --port 8000
```

Test:
```bash
curl "http://127.0.0.1:8000/health"
curl "http://127.0.0.1:8000/set?A=0.5&B=0.2"
```

---

## Fels√∂kning

### Kamera upptagen (Device or resource busy)
N√•gon annan process h√•ller kameran:
```bash
sudo fuser -v /dev/video0 /dev/video1
sudo lsof /dev/video0
sudo lsof /dev/video1
```

### V4L2 ‚ÄúInvalid argument‚Äù (VIDIOC_REQBUFS)
Vissa UVC-kameror beh√∂ver att man tvingar format (oftast `mjpeg`) och/eller anv√§nder r√§tt video-node.
- Testa `/dev/video1`
- Testa `mjpeg` i ffmpeg:

```bash
ffmpeg -hide_banner -loglevel error \
  -f v4l2 -input_format mjpeg -video_size 640x480 -i /dev/video0 \
  -frames:v 1 -q:v 4 -y /tmp/frame.jpg
```

Om detta funkar men systemd-loop failar:
- s√§tt `SNAP_INPUT_FORMAT=mjpeg` i `relai-vision-loop.service`
- och/eller `VIDEO_DEVS=/dev/video0,/dev/video1`

---

## S√§kerhet / ‚ÄúPush-s√§kert‚Äù
Filer som **aldrig** ska in i git:
- `.venv/`
- `.relai_secrets`

L√§gg i `.gitignore`:
```gitignore
.venv/
.relai_secrets
__pycache__/
*.pyc
```

---

## 2DO (n√§sta steg)

### Stabilitet & drift
- [ ] S√§kerst√§ll att `relai-vision-loop.service` √§r stabil (mjpeg + ev `/dev/video1`)
- [ ] L√§gg in ‚Äúsingle instance‚Äù-l√•s (flock) i vision-loop service om inte redan gjort
- [ ] L√§gg in b√§ttre loggning/metrics (t.ex. ‚Äúsnap_format_used‚Äù, ‚Äúvideo_dev_used‚Äù i HA-attribut)

### Home Assistant (nytta)
- [ ] Byt audio-output fr√•n mini-dashboard ‚Üí **HA-sensorer** (REST API states eller MQTT)
- [ ] Skapa en ‚ÄúLive‚Äù-dashboard i HA med:
  - `vision_top_label`, `top_score`, `person_count`, `total_ms`
  - audio-score (A/B) som graf eller gauge
- [ ] Skapa automation: ‚Äúperson i bild‚Äù ‚Üí notifiering / logg / assist

### Produktifiera repot
- [ ] Dokumentera exakt hur `vision-service` byggs/k√∂rs (Dockerfile/compose)
- [ ] L√§gg in ‚ÄúQuickstart‚Äù-script (makefile eller `./scripts/`)
- [ ] L√§gg in ‚Äúknown-good‚Äù versions (Debian, container-tag, modellfilnamn, osv)

### N√§sta delprojekt (valfritt)
- [ ] Speaker ID (separat modell + enrollment) ‚Üí `sensor.speaker` + `sensor.speaker_confidence`
- [ ] Privacy & samtycke: tydlig policy/README-sektion om vad som lagras, vad som inte lagras

---

## Snabbkommandon (bra att ha)

```bash
# vision-service health
curl -sS http://127.0.0.1:5052/health ; echo

# snapshot
ffmpeg -hide_banner -loglevel error -f v4l2 -video_size 640x480 -i /dev/video0 -frames:v 1 -q:v 4 -y /tmp/frame.jpg

# infer
curl -sS -F "file=@/tmp/frame.jpg" http://127.0.0.1:5052/infer | head -c 400; echo

# vision-loop logg
journalctl -u relai-vision-loop.service -f

# audio-loop logg
journalctl -u relai-audio-loop.service -f
```
